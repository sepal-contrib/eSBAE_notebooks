{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e23314bf-64fc-4ffc-9407-b8b1fe6666b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import numpy as np\n",
    "from sampling_handler.misc import py_helpers\n",
    "from sampling_handler.time_series import change_detections\n",
    "from retrying import retry\n",
    "\n",
    "import ee\n",
    "ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53a6b7f-eadc-415b-89ec-b20e3155ce4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_segments(ccdcAst, mask_1d):\n",
    "    \"\"\" \"\"\"\n",
    "    bands_2d = ccdcAst.select(\".*_coefs\").bandNames()\n",
    "    bands_1d = ccdcAst.bandNames().removeAll(bands_2d)\n",
    "    segment_1d = ccdcAst.select(bands_1d).arrayMask(mask_1d)\n",
    "    mask_2d = mask_1d.arrayReshape(ee.Image(ee.Array([-1, 1])), 2)\n",
    "    segment_2d = ccdcAst.select(bands_2d).arrayMask(mask_2d)\n",
    "    return segment_1d.addBands(segment_2d)\n",
    "\n",
    "\n",
    "def get_segment(ccdcAst, mask_1d):\n",
    "    \"\"\" \"\"\"\n",
    "    bands_2d = ccdcAst.select(\".*_coefs\").bandNames()\n",
    "    bands_1d = ccdcAst.bandNames().removeAll(bands_2d)\n",
    "    segment_1d = ccdcAst.select(bands_1d).arrayMask(mask_1d).arrayGet([0])\n",
    "    mask_2d = mask_1d.arrayReshape(ee.Image(ee.Array([-1, 1])), 2)\n",
    "    segment_2d = ccdcAst.select(bands_2d).arrayMask(mask_2d).arrayProject([1])\n",
    "    return segment_1d.addBands(segment_2d)\n",
    "\n",
    "\n",
    "def transform_date(date):\n",
    "    \"\"\" \"\"\"\n",
    "    date = pd.to_datetime(dt.fromtimestamp(date / 1000.0))\n",
    "    dates_float = date.year + np.round(date.dayofyear / 365, 3)\n",
    "    dates_float = 0 if dates_float == \"1970.003\" else dates_float\n",
    "    return dates_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "983898c0-dc0c-4b18-941c-a6b7dc765f21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "point_id_name = 'point_id'\n",
    "\n",
    "# start of calibration period (mainly for bfast)\n",
    "start_calibration = \"2013-01-01\"  # YYYY-MM-DD format\n",
    "\n",
    "# Actual period of interest, i.e. monitoring period\n",
    "start_monitor =     \"2019-01-01\"  # YYYY-MM-DD format\n",
    "end_monitor =       \"2023-01-01\"  # YYYY-MM-DD format\n",
    "\n",
    "# Directory where output and temp files will go\n",
    "outdir = 'results'  # goes to module_results/sbae_point_analysis if set to None\n",
    "\n",
    "# Select algorithms to run (Treu or False)\n",
    "cusum_deforest =  False\n",
    "bfast_monitor =   False\n",
    "bs_slope =        False\n",
    "ts_metrics =      False\n",
    "ccdc =            True\n",
    "landtrendr =      False\n",
    "jrc_nrt =         False\n",
    "global_products = False\n",
    "\n",
    "# select the bands to extract\n",
    "bands = ['green', 'red', 'nir', 'swir1', 'swir2', 'ndfi'] # other choices: ndfi, ndmi, mndwi, brightness, greenness, wetness\n",
    "\n",
    "# select the band for univariate ts-analysis (has to be inside bands list)\n",
    "ts_band = 'ndfi'\n",
    "\n",
    "# select the resolution to which the satellite data will be resized.\n",
    "scale = 70  # in meters (70 m is half ha, relates to FAO forest definition)\n",
    "\n",
    "### DO NOT CHANGE YET ###\n",
    "satellite='Landsat'  # this is going to be Surface Reflactance, Collection 2, Tier 1 data only\n",
    "max_cloud_cover = 75  # in percentage (0-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9417831-747c-4cf8-95cb-a6ea2e840c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# landsat related parameters\n",
    "lsat_params = {\n",
    "    'l9':     True,\n",
    "    'l8':     True,\n",
    "    'l7':     True,\n",
    "    'l5':     True,\n",
    "    'l4':     True,\n",
    "    'brdf':   True,\n",
    "    'bands':  bands,\n",
    "    'max_cc': max_cloud_cover\n",
    "}\n",
    "\n",
    "# bfast parameters\n",
    "bfast_params = {\n",
    "    'run':           bfast_monitor,\n",
    "    'start_monitor': start_monitor, \n",
    "    'freq':          365,\n",
    "    'k':             3, \n",
    "    'hfrac':         0.25, \n",
    "    'trend':         True, \n",
    "    'level':         0.05, \n",
    "    'backend':       'python'\n",
    "}\n",
    "\n",
    "# cusum parameters\n",
    "cusum_params = {\n",
    "    'run':              cusum_deforest,\n",
    "    'nr_of_bootstraps': 1000\n",
    "}\n",
    "\n",
    "# slope parameters\n",
    "bs_slope_params = {\n",
    "    'run':              bs_slope,\n",
    "    'nr_of_bootstraps': 1000\n",
    "}\n",
    "\n",
    "# time-series metrics\n",
    "ts_metrics_params = {\n",
    "    'run':              ts_metrics,\n",
    "    'outlier_removal':  False,\n",
    "    'z_threshhold':     3\n",
    "}\n",
    "\n",
    "# ccdc parameters\n",
    "ccdc_params = {\n",
    "    'run':                   ccdc,\n",
    "    'breakpointBands':       ['green', 'red', 'nir', 'swir1', 'swir2'],\n",
    "    'tmaskBands':            ['green', 'swir2'],\n",
    "    'minObservations':       6,\n",
    "    'chiSquareProbability':  .99,\n",
    "    'minNumOfYearsScaler':   1,\n",
    "    'dateFormat':            2,\n",
    "    'lambda':                20,\n",
    "    'maxIterations':         1000\n",
    "}\n",
    "\n",
    "\n",
    "landtrendr_params = { \n",
    "        'run':                    landtrendr,\n",
    "        'maxSegments':            6,\n",
    "        'spikeThreshold':         0.9,\n",
    "        'vertexCountOvershoot':   3,\n",
    "        'preventOneYearRecovery': True,\n",
    "        'recoveryThreshold':      0.25,\n",
    "        'pvalThreshold':          0.05,\n",
    "        'bestModelProportion':    0.75,\n",
    "        'minObservationsNeeded':  3\n",
    "}\n",
    "\n",
    "jrc_nrt_params = {\n",
    "    'run': jrc_nrt\n",
    "}\n",
    "\n",
    "# global products parameters\n",
    "global_products = {\n",
    "    'run':                      global_products,\n",
    "    'gfc':                      True,     # will include tree-cover 2000, loss, gain, lossyear\n",
    "    'tmf':                      True,    # will include deforestation and degradation year for tropical moist forests\n",
    "    'tmf_years':                True,    # will include classes per year - according to the monitor period\n",
    "    'esa_lc20':                 True,    # will include ESA LandCover Product class\n",
    "    'copernicus_lc':            True,    # will include ESA LandCover Product class - acording to the monitoring years\n",
    "    'esri_lc':                  True,    # will include the classes from ESRI World Cover 2020\n",
    "    'lang_tree_height':         True,    # returns the Tree Height from Lang et al 2022\n",
    "    'potapov_tree_height':      True,    # returns the tree height from Potapov et al. 2019 \n",
    "    'elevation':                True,    # returns elevation, slope and aspect\n",
    "    'dynamic_world_tree_prob':  True,    # returns Min, Max, Mean and StdDev of the trees probability for the monitoring period\n",
    "    'dynamic_world_class_mode': True     # returns the mode of the class for the monitoring period   \n",
    "}\n",
    "\n",
    "### DO NOT CHANGE ###\n",
    "### GATHER ALL INFO INTO A DICT #####\n",
    "config_dict = {\n",
    "    'work_dir':                         outdir,\n",
    "    'workers':                          500,\n",
    "    'file_accumulation':                25000,\n",
    "    'max_points_per_chunk':             250,\n",
    "    'grid_size_levels':                 [4, 2, 1, 0.5, 0.25, 0.125, 0.075],  # definition of chunk sizes in degrees  \n",
    "    'lsat_params':                      lsat_params,\n",
    "    'ts_params': {\n",
    "        'start_calibration':            start_calibration,\n",
    "        'start_monitor':                start_monitor,\n",
    "        'end_monitor':                  end_monitor,\n",
    "        'point_id':                     point_id_name,\n",
    "        'bands':                        bands,\n",
    "        'ts_band':                      ts_band,\n",
    "        'satellite':                    satellite,\n",
    "        'scale':                        scale,\n",
    "        'max_cc':                       max_cloud_cover,\n",
    "        'outlier_removal':              True,\n",
    "        'smooth_ts':                    True       \n",
    "    },    \n",
    "    'bfast_params':                     bfast_params,\n",
    "    'cusum_params':                     cusum_params,\n",
    "    'bs_slope_params':                  bs_slope_params,\n",
    "    'ts_metrics_params':                ts_metrics_params,\n",
    "    'ccdc_params':                      ccdc_params,\n",
    "    'landtrendr_params':                landtrendr_params,\n",
    "    'jrc_nrt_params':                   jrc_nrt_params,\n",
    "    'global_products':                  global_products\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad3854a-af29-423f-9026-25d169d1b774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulated batch 1 of files\n"
     ]
    }
   ],
   "source": [
    "ts_dir = Path('/home/sepal-user/test_esbae/results/Landsat')\n",
    "files = list(ts_dir.glob('*geojson'))\n",
    "\n",
    "p, j, to_concat = 0, 0, []\n",
    "for i, file in enumerate(files):\n",
    "\n",
    "    gdf = py_helpers.geojson_to_gdf(file, convert_dates=True)\n",
    "    p += len(gdf)\n",
    "    to_concat.append(gdf)\n",
    "\n",
    "    if p > 2000:\n",
    "        # accumulate files to dataframe until length is reached\n",
    "        print(f'Accumulated batch {j+1} of files')\n",
    "        # run change routine on accumulated files\n",
    "        cdf = pd.concat(to_concat)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa43ce7b-2ed7-4873-b2cb-df8d8805159d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 µs, sys: 0 ns, total: 19 µs\n",
      "Wall time: 22.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "@retry(stop_max_attempt_number=3, wait_random_min=5000, wait_random_max=10000)\n",
    "def run_ccdc(df, samples, config_dict):\n",
    "    ccdc_params = config_dict[\"ccdc_params\"]\n",
    "    ts_band = config_dict[\"ts_params\"][\"ts_band\"]\n",
    "    bands = config_dict[\"ts_params\"][\"bands\"]\n",
    "    point_id_name = config_dict[\"ts_params\"][\"point_id\"]\n",
    "\n",
    "    start_calibration = config_dict[\"ts_params\"][\"start_calibration\"]\n",
    "    start_monitor = config_dict[\"ts_params\"][\"start_monitor\"]\n",
    "    end_monitor = config_dict[\"ts_params\"][\"end_monitor\"]\n",
    "    scale = config_dict[\"ts_params\"][\"scale\"]\n",
    "\n",
    "    #args_list, iColl, points = [], None, None\n",
    "    args_list, iColl, points = [], None, []\n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        # get dates\n",
    "        dates = ee.List([dt.strftime(date, \"%Y-%m-%d\") for date in row.dates])\n",
    "\n",
    "        # transform ts dict into way to ingest into imagery\n",
    "        ts = []\n",
    "        for j in range(len(row.dates)):\n",
    "            ts.append([v[j] for v in row.ts.values()])\n",
    "\n",
    "        # gather points for feature collection to reduce on\n",
    "        geom = ee.Feature(\n",
    "            row.geometry.__geo_interface__\n",
    "        ).set(point_id_name, row[point_id_name])\n",
    "        squared = geom.geometry().buffer(100, 10).bounds()\n",
    "        points.append(row[point_id_name])\n",
    "\n",
    "        # merge dates with ts data\n",
    "        ts = ee.List(ts).zip(dates)\n",
    "\n",
    "        def zip_to_image(element):\n",
    "\n",
    "            values = ee.List(element).get(0)\n",
    "            date = ee.List(element).get(1)\n",
    "\n",
    "            return ee.Image(\n",
    "                ee.Image.constant(values)\n",
    "                .rename(list(row.ts.keys()))\n",
    "                .clip(squared)\n",
    "                .set(\"system:time_start\", ee.Date.parse(\"YYYY-MM-dd\", date).millis())\n",
    "                .toFloat()\n",
    "            )\n",
    "\n",
    "        # create the image collection\n",
    "        tsee = ee.ImageCollection(ts.map(zip_to_image))\n",
    "        iColl = iColl.cat(tsee.toList(tsee.size())) if iColl else tsee.toList(tsee.size())\n",
    "\n",
    "    points = samples.filter(ee.Filter.inList(point_id_name, points))\n",
    "    #print(points.getInfo())\n",
    "    iColl = ee.ImageCollection.fromImages(iColl)\n",
    "\n",
    "    # add collection and remove run from parameter dict\n",
    "    ccdc_params.update(collection=iColl)\n",
    "    ccdc_params.pop(\"run\", None)\n",
    "\n",
    "    # run ccdc\n",
    "    ccdc = ee.Algorithms.TemporalSegmentation.Ccdc(**ccdc_params)\n",
    "\n",
    "    # extract info\n",
    "    # create array of start of monitoring in shape of tEnd\n",
    "    tEnd = ccdc.select(\"tEnd\")\n",
    "    mon_date_array_start = tEnd.multiply(0).add(ee.Date(start_monitor).millis())\n",
    "    mon_date_array_end = tEnd.multiply(0).add(ee.Date(end_monitor).millis())\n",
    "\n",
    "    # create the date mask\n",
    "    date_mask = tEnd.gte(mon_date_array_start).And(tEnd.lte(mon_date_array_end))\n",
    "\n",
    "    # use date mask to mask all of ccdc\n",
    "    monitoring_ccdc = get_segments(ccdc, date_mask)\n",
    "\n",
    "    # mask for highest magnitude in monitoring period\n",
    "    magnitude = monitoring_ccdc.select(f'{ts_band}_magnitude')\n",
    "    max_abs_magnitude = (\n",
    "    magnitude.abs()\n",
    "        .arrayReduce(ee.Reducer.max(), [0])\n",
    "        .arrayGet([0])\n",
    "        .rename(\"max_abs_magnitude\")\n",
    "        )\n",
    "\n",
    "    mask = magnitude.abs().eq(max_abs_magnitude)\n",
    "    segment = get_segment(monitoring_ccdc, mask)\n",
    "    magnitude = ee.Image(segment.select([f'{ts_band}_magnitude', \"tBreak\", \"tEnd\"]))\n",
    "\n",
    "    def pixel_value_nan(feature):\n",
    "        pixel_value = ee.List([feature.get(f'{ts_band}_magnitude'), -9999]).reduce(\n",
    "            ee.Reducer.firstNonNull()\n",
    "        )\n",
    "        return feature.set({f'{ts_band}_magnitude': pixel_value})\n",
    "\n",
    "    sampled_points = magnitude.reduceRegions(**{\n",
    "            \"reducer\": ee.Reducer.first(),\n",
    "            \"collection\": points,\n",
    "            \"scale\": 100,\n",
    "            \"tileScale\": 4,\n",
    "        }).map(pixel_value_nan).select(\n",
    "            propertySelectors=[point_id_name, f'{ts_band}_magnitude', \"tBreak\", \"tEnd\"],\n",
    "            retainGeometry=False\n",
    "    )\n",
    "\n",
    "    url = sampled_points.getDownloadUrl(\"geojson\")\n",
    "    \n",
    "    # Handle downloading the actual pixels.\n",
    "    r = requests.get(url, stream=True)\n",
    "    if r.status_code != 200:\n",
    "        raise r.raise_for_status()\n",
    "\n",
    "    return pd.DataFrame([feature['properties'] for feature in r.json()['features']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91d36c06-963c-4b63-880f-7e908b0dab34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 1.04 s, total: 1min 10s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndfi_magnitude</th>\n",
       "      <th>point_id</th>\n",
       "      <th>tBreak</th>\n",
       "      <th>tEnd</th>\n",
       "      <th>ccdc_change_date</th>\n",
       "      <th>ccdc_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>129186</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.671235e+12</td>\n",
       "      <td>1970.003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10575.805899</td>\n",
       "      <td>129187</td>\n",
       "      <td>1.578614e+12</td>\n",
       "      <td>1.577923e+12</td>\n",
       "      <td>2020.027</td>\n",
       "      <td>10575.805899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8330.556694</td>\n",
       "      <td>129188</td>\n",
       "      <td>1.577232e+12</td>\n",
       "      <td>1.575158e+12</td>\n",
       "      <td>2019.984</td>\n",
       "      <td>8330.556694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1748.045874</td>\n",
       "      <td>129358</td>\n",
       "      <td>1.671235e+12</td>\n",
       "      <td>1.669853e+12</td>\n",
       "      <td>2022.962</td>\n",
       "      <td>1748.045874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>129359</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.671235e+12</td>\n",
       "      <td>1970.003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1788.632778</td>\n",
       "      <td>313042</td>\n",
       "      <td>1.671754e+12</td>\n",
       "      <td>1.670371e+12</td>\n",
       "      <td>2022.978</td>\n",
       "      <td>1788.632778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>313043</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.672445e+12</td>\n",
       "      <td>1970.003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-712.295607</td>\n",
       "      <td>313111</td>\n",
       "      <td>1.672445e+12</td>\n",
       "      <td>1.670371e+12</td>\n",
       "      <td>2023.000</td>\n",
       "      <td>-712.295607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>313180</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.670371e+12</td>\n",
       "      <td>1970.003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-396.161840</td>\n",
       "      <td>313316</td>\n",
       "      <td>1.672445e+12</td>\n",
       "      <td>1.670371e+12</td>\n",
       "      <td>2023.000</td>\n",
       "      <td>-396.161840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ndfi_magnitude  point_id        tBreak          tEnd  ccdc_change_date  \\\n",
       "0         0.000000    129186  0.000000e+00  1.671235e+12          1970.003   \n",
       "1     10575.805899    129187  1.578614e+12  1.577923e+12          2020.027   \n",
       "2      8330.556694    129188  1.577232e+12  1.575158e+12          2019.984   \n",
       "3      1748.045874    129358  1.671235e+12  1.669853e+12          2022.962   \n",
       "4         0.000000    129359  0.000000e+00  1.671235e+12          1970.003   \n",
       "..             ...       ...           ...           ...               ...   \n",
       "3      1788.632778    313042  1.671754e+12  1.670371e+12          2022.978   \n",
       "4         0.000000    313043  0.000000e+00  1.672445e+12          1970.003   \n",
       "5      -712.295607    313111  1.672445e+12  1.670371e+12          2023.000   \n",
       "6         0.000000    313180  0.000000e+00  1.670371e+12          1970.003   \n",
       "7      -396.161840    313316  1.672445e+12  1.670371e+12          2023.000   \n",
       "\n",
       "    ccdc_magnitude  \n",
       "0         0.000000  \n",
       "1     10575.805899  \n",
       "2      8330.556694  \n",
       "3      1748.045874  \n",
       "4         0.000000  \n",
       "..             ...  \n",
       "3      1788.632778  \n",
       "4         0.000000  \n",
       "5      -712.295607  \n",
       "6         0.000000  \n",
       "7      -396.161840  \n",
       "\n",
       "[2008 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "samples = ee.FeatureCollection('users/andreasvollrath/eth_ts_analysis/ethiopia_hex_centroids_dggrid_15')\n",
    "\n",
    "ccdc_args = []\n",
    "for i in range(0, len(cdf), 10):\n",
    "    ccdc_args.append([cdf.iloc[i:i+10], samples, config_dict])\n",
    "\n",
    "result = py_helpers.run_in_parallel(run_ccdc, ccdc_args, workers=20)\n",
    "gdf = pd.concat(result)\n",
    "gdf[\"ccdc_change_date\"] = gdf[\"tBreak\"].apply(lambda x: transform_date(x))\n",
    "gdf[\"ccdc_magnitude\"] = gdf[f\"ndfi_magnitude\"]\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a5104-ef47-4d81-9471-00a3bf6ccc58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pre_esbae",
   "language": "python",
   "name": "pre_esbae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
