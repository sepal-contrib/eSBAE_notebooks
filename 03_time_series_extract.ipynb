{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e262b60-a61c-4fb6-adfb-c00d1ebda073",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>eSBAE - Notebook Series - Part 3, version 0.4, March 2023. Andreas Vollrath, UN-Food and Agricultural Organization, Rome</i>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64fe01-50b8-4280-9629-1445ad541e45",
   "metadata": {},
   "source": [
    "![title](images/header.png)\n",
    "\n",
    "# III - eSBAE Time-Series Extraction\n",
    "### Extract various time-series data for large sets of points from Google Earth Engine\n",
    "-------\n",
    "\n",
    "This notebook takes you through the process of extracting time-series for a set of points using [Google Earth Engine](https://earthengine.google.com/). The script is optimized to deal with thousands of points and will use parallelization to efficiently extract the information from the platform.\n",
    "\n",
    "**You will need**:\n",
    "- a valid Earth Engine account ([sign up here](https://code.earthengine.google.com/register))\n",
    "- an uploaded table of points (Feature Collection) \n",
    "- the table needs a unique point identifier (Point ID)\n",
    "\n",
    "**You should be aware, that:** \n",
    "\n",
    "- As a SEPAL user: this notebook does **not need huge resources**, as processing is done on the platform. An **m2 instance** is best suited.  \n",
    "- The extraction can take up to days (>100000 points). If you are on SEPAL, make use of the **\"keep instance running\"** option within the user report dashboard.\n",
    "  - You do this by clicking on the cost per hour shown at the bottom right of your screen. Select the edit button on the right side under \"sessions\", then move the slider to the right until several days are selected and close the window. However, **do not forget** to shut down your machine once processing finished. \n",
    "- Interruption of connectivity to the SEPAL server may block the output of the Jupyter notebook. **This does not mean the processing stopped.** A logfile is created within your \"tmp\" folder where you can check if there is an issue. You can see in esbae_log_(time) if the processing is still ongoing.\n",
    "  - Go to your \"tmp\" folder by making sure the File Browser icon is selected from the four tabs on the left of your Jupyter Notebooks screen, then click on the folder icon on the far left of the displayed path to your working folder. This will take you one directory up from your working folder where the \"tmp\" folder is located. Inside the \"tmp\" folder you can see the \"Last Modified\" times. Check to see that the last modified time was within the last few minutes when you ran the code cell (proving the processing is still ongoing). If the last modified time seems too long ago, try checking whether your instance is still active (there should be a non-zero cost per hour on the bottom of your screen) and then restarting the kernel and running all the cells again.\n",
    "- If you restart the kernel and execute all cells, **extraction will start where it stopped**. This is also valid if your instance has been shut down before processing was completely finished."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f9d9a-8a0d-4d85-b134-f0bda3727152",
   "metadata": {},
   "source": [
    "### 1 - Import libraries \n",
    "This cell will provide us with the functionality we need for running the subsequent cells of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75e78de-8687-4632-8586-9ca964b31045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/jupyter/kernels/venv-eSBAE_notebooks/venv/lib/python3.10/site-packages/bfast/__init__.py:10: UserWarning: cupy is not available in this environment, GPU fonctionnalities won't be available\n",
      "  warn(\"cupy is not available in this environment, GPU fonctionnalities won't be available\")\n"
     ]
    }
   ],
   "source": [
    "# initialize EE    \n",
    "import ee\n",
    "try:\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "    \n",
    "from sampling_handler import TimeSeriesExtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c04e79-5bfe-48d9-8412-c17707d7c5e9",
   "metadata": {},
   "source": [
    "### 2 - Basic Input Variables\n",
    "\n",
    "Here a so called class instance is initialized. The class instance needs some parameters to be set and is written into the *esbae* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c8d21f-1d84-44b2-9b44-3458bc7ff444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using existing project directory at /home/sepal-user/module_results/esbae/esbae_project_Jan25\n",
      "INFO: Using existent config file from project directory /home/sepal-user/module_results/esbae/esbae_project_Jan25\n"
     ]
    }
   ],
   "source": [
    "esbae = TimeSeriesExtraction(\n",
    "    # your project name that you use for all of the notebooks (NEEDS to stay consistent)\n",
    "    project_name  = 'my_first_esbae_project',\n",
    "    \n",
    "    # your start and end date \n",
    "    #  NOTE: this start date should go further back in the past than the \n",
    "    # envisaged monitoring period for calibration purposes\n",
    "    ts_start      = '2015-01-01',      # YYYY-MM-DD format\n",
    "    ts_end        = '2023-01-01',        # YYYY-MM-DD format\n",
    "    \n",
    "    # satellite platform (for now only Landsat is supported)\n",
    "    satellite     = 'Landsat',\n",
    "    \n",
    "    # at what resolution in metres you want to extract (shall conform with forest definition MMU)\n",
    "    scale         = 70, # pixel size in metres\n",
    "    \n",
    "    # wether the TS will be extracted on a bounding box with diameter scale with original scale (e.g 30m for Landsat) of the underlying data (True), \n",
    "    # or if the underlying data is rescaled to the scale (False)\n",
    "    # setting it to True might be more accurate, but tends to be slower\n",
    "    bounds_reduce = False,\n",
    "    \n",
    "    # bands\n",
    "    bands         =  [\n",
    "        'green', 'red', 'nir', 'swir1', 'swir2',   # reflectance bands\n",
    "        'ndfi', #'ndmi', 'ndvi',                    # indices\n",
    "        'brightness', 'greenness', 'wetness'       # Tasseled Cap \n",
    "    ], \n",
    "    # This is in case you haven't run notebook 1 and 2, and want to directly start from here with a defined points file\n",
    "    # aoi = ee.FeatureCollection(ee.FeatureCollection('users/username/my_points').geometry().convexHull(100))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4dc5b2-3d18-429e-ae4a-5b16f677448a",
   "metadata": {},
   "source": [
    "### 3 - Landsat parameters\n",
    "\n",
    "Here you can select which satellites you want to include from the Landsat mission.\n",
    "In addition you can select the BRDF correction and a filter for maximum cloud cover. Note that the bands parameter is already set in the initialization and will be taken from the class attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d1fb79-897c-4a86-9b02-16e2c7d85758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# landsat related parameters\n",
    "lsat_params = {\n",
    "    'l9': True,\n",
    "    'l8': True,\n",
    "    'l7': True,\n",
    "    'l5': True,\n",
    "    'l4': True,\n",
    "    'brdf': True,\n",
    "    'bands': esbae.bands,\n",
    "    'max_cc': 75    # percent\n",
    "} \n",
    "\n",
    "# apply the basic configuration set in the cell above\n",
    "esbae.lsat_params = lsat_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83cb8d-3f49-4bdf-ae77-25b1b13a6de3",
   "metadata": {},
   "source": [
    "### 4 - Processing parameters\n",
    "\n",
    "Here you can refine the parallelization options. For efficient extraction, the time-series extraction is done on chunks of data, defined by squared grids of given sizes. The routine will check how many points are in each chunk. If this is below the max_points_per_chunk, it will go on and process those points. Otherwise it will try to process those points at a lower grid size level. Some optimized settings are given below, comment and uncomment as appropriate. Uncomment the lines by removing the #."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c99611d-a405-49c1-941f-4700cda2e61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "esbae.workers = 10                   # this defines how many parallel requests will be send to EarthEngine at a time\n",
    "esbae.max_points_per_chunk = 100     # this defines the maximum amount of points as send per request to Earth Engine at a time\n",
    "\n",
    "# this defines the chunk sizes (in degree) to create the requests\n",
    "#esbae.grid_size_levels = [0.1, 0.075, 0.05]   # optimized for 1km systematic grid\n",
    "esbae.grid_size_levels = [0.2, 0.15, 0.1]    # optimized for 2km systematic grid\n",
    "#esbae.grid_size_levels = [0.4, 0.3, 0.2]     # optimized for 4km systematic grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae865d-43bf-495b-b6ce-e8be7fd12884",
   "metadata": {},
   "source": [
    "### 5 - Set a custom grid (optional)\n",
    "\n",
    "This step is only necessary if you skipped notebook 2. You then need to define an Earth Engine feature collection as well as the unique point identifier. Uncomment the lines by removing the #."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786e8355-4b7e-4f47-8a30-62ad5d8321c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# esbae.sample_asset = 'users/username/my_already_existing_points'\n",
    "# esbae.pid = 'my_unique_point_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed4350-c397-43eb-ab7e-fe795a24c831",
   "metadata": {},
   "source": [
    "### 6 - Check for already processed data (optional)\n",
    "\n",
    "This is useful for large points sizes and when the connection to Sepal gets interrupted. Usually processing will continue, but it is not straightforward to track progress. \n",
    "You can instead restart the kernel, execute all cells and see if processing has been finished with the following line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad269ed4-9e28-4d4b-a629-d05513d41376",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Verifying the number of points for which the time-series have already been extracted...\n",
      "INFO: No time-series data has been extracted yet.\n"
     ]
    }
   ],
   "source": [
    "esbae.check_if_completed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5c28df-5381-413c-924d-23830b97b87e",
   "metadata": {},
   "source": [
    "### 7 - Run the time-series data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ccf187-bba1-4e1a-a493-d646f51b9fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Verifying parameter settings...\n",
      "INFO: Preparing the processing of 178 points.\n",
      "INFO: No time-series data has been extracted yet.\n",
      "INFO: Create AOI from points and upload as temporary EE asset inside tmp_esbae_250115_190025.\n",
      "INFO: Creating processing chunks of 0.2 degrees for parallel extraction.\n",
      "INFO: Preparing the parallel extraction over a total of 112 chunks. This may take a while...\n",
      "INFO: Starting the parallel extraction routine.\n",
      "INFO: Extracting 1 points for chunk nr 0 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 6 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 5 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 4 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 2 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 8 at resolution 0.2\n",
      "INFO: Extracting 2 points for chunk nr 1 at resolution 0.2\n",
      "INFO: Extracting 2 points for chunk nr 7 at resolution 0.2\n",
      "INFO: Extracting 2 points for chunk nr 9 at resolution 0.2\n",
      "INFO: Extracting 2 points for chunk nr 3 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 8 at resolution 0.2 extracted in:: 0:00:21.488579\n",
      "INFO: Extracting 2 points for chunk nr 10 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 9 at resolution 0.2 extracted in:: 0:00:22.718396\n",
      "INFO: Extracting 1 points for chunk nr 11 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 0 at resolution 0.2 extracted in:: 0:00:31.097971\n",
      "INFO: 1 points for chunk nr 6 at resolution 0.2 extracted in:: 0:00:31.613404\n",
      "INFO: 2 points for chunk nr 3 at resolution 0.2 extracted in:: 0:00:31.477743\n",
      "INFO: Extracting 2 points for chunk nr 12 at resolution 0.2\n",
      "INFO: Extracting 2 points for chunk nr 13 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 14 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 4 at resolution 0.2 extracted in:: 0:00:32.766321\n",
      "INFO: Extracting 2 points for chunk nr 15 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 2 at resolution 0.2 extracted in:: 0:00:44.485694\n",
      "INFO: Extracting 2 points for chunk nr 16 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 7 at resolution 0.2 extracted in:: 0:00:47.590677\n",
      "INFO: Extracting 1 points for chunk nr 17 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 1 at resolution 0.2 extracted in:: 0:00:53.088917\n",
      "INFO: Extracting 2 points for chunk nr 18 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 5 at resolution 0.2 extracted in:: 0:00:55.865686\n",
      "INFO: Extracting 1 points for chunk nr 19 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 15 at resolution 0.2 extracted in:: 0:00:25.190145\n",
      "INFO: Extracting 1 points for chunk nr 20 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 14 at resolution 0.2 extracted in:: 0:00:30.494393\n",
      "INFO: 1 points for chunk nr 11 at resolution 0.2 extracted in:: 0:00:39.667365\n",
      "INFO: Extracting 1 points for chunk nr 21 at resolution 0.2\n",
      "INFO: Extracting 3 points for chunk nr 22 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 13 at resolution 0.2 extracted in:: 0:00:32.643584\n",
      "INFO: Extracting 3 points for chunk nr 23 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 10 at resolution 0.2 extracted in:: 0:00:51.684853\n",
      "INFO: Extracting 2 points for chunk nr 24 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 21 at resolution 0.2 extracted in:: 0:00:23.866239\n",
      "INFO: Extracting 1 points for chunk nr 25 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 18 at resolution 0.2 extracted in:: 0:00:34.274023\n",
      "INFO: Extracting 1 points for chunk nr 26 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 16 at resolution 0.2 extracted in:: 0:00:44.282364\n",
      "INFO: 1 points for chunk nr 19 at resolution 0.2 extracted in:: 0:00:32.976825\n",
      "INFO: Extracting 1 points for chunk nr 27 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 28 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 20 at resolution 0.2 extracted in:: 0:00:34.917821\n",
      "INFO: Extracting 2 points for chunk nr 29 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 12 at resolution 0.2 extracted in:: 0:01:09.444050\n",
      "INFO: Extracting 2 points for chunk nr 30 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 25 at resolution 0.2 extracted in:: 0:00:24.505694\n",
      "INFO: Extracting 1 points for chunk nr 31 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 17 at resolution 0.2 extracted in:: 0:01:04.799685\n",
      "INFO: Extracting 1 points for chunk nr 32 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 24 at resolution 0.2 extracted in:: 0:00:42.803683\n",
      "INFO: Extracting 2 points for chunk nr 33 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 28 at resolution 0.2 extracted in:: 0:00:37.404761\n",
      "INFO: Extracting 1 points for chunk nr 34 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 26 at resolution 0.2 extracted in:: 0:00:43.923117\n",
      "INFO: Extracting 2 points for chunk nr 35 at resolution 0.2\n",
      "INFO: 3 points for chunk nr 23 at resolution 0.2 extracted in:: 0:01:10.280139\n",
      "INFO: 1 points for chunk nr 27 at resolution 0.2 extracted in:: 0:00:46.464367\n",
      "INFO: Extracting 2 points for chunk nr 36 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 37 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 32 at resolution 0.2 extracted in:: 0:00:30.182248\n",
      "INFO: Extracting 1 points for chunk nr 38 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 31 at resolution 0.2 extracted in:: 0:00:32.771840\n",
      "INFO: Extracting 2 points for chunk nr 39 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 33 at resolution 0.2 extracted in:: 0:00:30.551231\n",
      "INFO: Extracting 1 points for chunk nr 40 at resolution 0.2\n",
      "INFO: 3 points for chunk nr 22 at resolution 0.2 extracted in:: 0:01:29.347692\n",
      "INFO: Extracting 2 points for chunk nr 41 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 29 at resolution 0.2 extracted in:: 0:01:13.079873\n",
      "INFO: Extracting 1 points for chunk nr 42 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 34 at resolution 0.2 extracted in:: 0:00:45.222191\n",
      "INFO: Extracting 2 points for chunk nr 43 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 30 at resolution 0.2 extracted in:: 0:01:15.135486\n",
      "INFO: Extracting 2 points for chunk nr 44 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 38 at resolution 0.2 extracted in:: 0:00:34.457673\n",
      "INFO: Extracting 1 points for chunk nr 45 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 41 at resolution 0.2 extracted in:: 0:00:33.433402\n",
      "INFO: Extracting 1 points for chunk nr 46 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 40 at resolution 0.2 extracted in:: 0:00:39.829931\n",
      "INFO: Extracting 2 points for chunk nr 47 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 39 at resolution 0.2 extracted in:: 0:00:46.661412\n",
      "INFO: Extracting 1 points for chunk nr 48 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 42 at resolution 0.2 extracted in:: 0:00:26.819386\n",
      "INFO: Extracting 2 points for chunk nr 49 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 37 at resolution 0.2 extracted in:: 0:01:01.832881\n",
      "INFO: Extracting 1 points for chunk nr 50 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 35 at resolution 0.2 extracted in:: 0:01:13.120234\n",
      "INFO: Extracting 3 points for chunk nr 51 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 45 at resolution 0.2 extracted in:: 0:00:36.062374\n",
      "INFO: Extracting 3 points for chunk nr 52 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 48 at resolution 0.2 extracted in:: 0:00:24.674603\n",
      "INFO: Extracting 1 points for chunk nr 53 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 43 at resolution 0.2 extracted in:: 0:00:45.650818\n",
      "INFO: Extracting 2 points for chunk nr 54 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 49 at resolution 0.2 extracted in:: 0:00:25.519611\n",
      "INFO: Extracting 1 points for chunk nr 55 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 50 at resolution 0.2 extracted in:: 0:00:22.830493\n",
      "INFO: 2 points for chunk nr 44 at resolution 0.2 extracted in:: 0:00:44.864436\n",
      "INFO: Extracting 3 points for chunk nr 56 at resolution 0.2\n",
      "INFO: Extracting 2 points for chunk nr 57 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 47 at resolution 0.2 extracted in:: 0:00:38.673698\n",
      "INFO: Extracting 2 points for chunk nr 58 at resolution 0.2\n",
      "INFO: 3 points for chunk nr 51 at resolution 0.2 extracted in:: 0:00:40.647038\n",
      "INFO: Extracting 2 points for chunk nr 59 at resolution 0.2\n",
      "INFO: 3 points for chunk nr 52 at resolution 0.2 extracted in:: 0:00:34.818075\n",
      "INFO: Extracting 2 points for chunk nr 60 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 55 at resolution 0.2 extracted in:: 0:00:35.596847\n",
      "INFO: Extracting 3 points for chunk nr 61 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 46 at resolution 0.2 extracted in:: 0:01:12.371680\n",
      "INFO: Extracting 1 points for chunk nr 62 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 53 at resolution 0.2 extracted in:: 0:00:44.576295\n",
      "INFO: Extracting 2 points for chunk nr 63 at resolution 0.2\n",
      "INFO: 3 points for chunk nr 56 at resolution 0.2 extracted in:: 0:00:40.988788\n",
      "INFO: Extracting 2 points for chunk nr 64 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 57 at resolution 0.2 extracted in:: 0:00:44.918759\n",
      "INFO: 2 points for chunk nr 58 at resolution 0.2 extracted in:: 0:00:39.203737\n",
      "INFO: Extracting 1 points for chunk nr 65 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 59 at resolution 0.2 extracted in:: 0:00:22.871603\n",
      "INFO: Extracting 1 points for chunk nr 67 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 54 at resolution 0.2 extracted in:: 0:00:51.726924\n",
      "INFO: Extracting 2 points for chunk nr 68 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 62 at resolution 0.2 extracted in:: 0:00:27.838593\n",
      "INFO: Extracting 1 points for chunk nr 69 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 36 at resolution 0.2 extracted in:: 0:02:32.967203\n",
      "INFO: Extracting 2 points for chunk nr 70 at resolution 0.2\n",
      "INFO: Extracting 2 points for chunk nr 66 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 65 at resolution 0.2 extracted in:: 0:00:26.630370\n",
      "INFO: Extracting 1 points for chunk nr 71 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 63 at resolution 0.2 extracted in:: 0:00:36.506902\n",
      "INFO: Extracting 2 points for chunk nr 72 at resolution 0.2\n",
      "INFO: 3 points for chunk nr 61 at resolution 0.2 extracted in:: 0:00:46.719125\n",
      "INFO: Extracting 2 points for chunk nr 73 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 67 at resolution 0.2 extracted in:: 0:00:40.589433\n",
      "INFO: Extracting 1 points for chunk nr 74 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 60 at resolution 0.2 extracted in:: 0:01:03.865243\n",
      "INFO: Extracting 2 points for chunk nr 75 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 70 at resolution 0.2 extracted in:: 0:00:33.608805\n",
      "INFO: Extracting 1 points for chunk nr 76 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 68 at resolution 0.2 extracted in:: 0:00:54.983684\n",
      "INFO: Extracting 1 points for chunk nr 77 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 71 at resolution 0.2 extracted in:: 0:00:33.563581\n",
      "INFO: 2 points for chunk nr 66 at resolution 0.2 extracted in:: 0:00:36.953369\n",
      "INFO: Extracting 2 points for chunk nr 78 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 79 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 72 at resolution 0.2 extracted in:: 0:00:34.090852\n",
      "INFO: 1 points for chunk nr 74 at resolution 0.2 extracted in:: 0:00:22.935471\n",
      "INFO: Extracting 2 points for chunk nr 80 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 81 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 69 at resolution 0.2 extracted in:: 0:00:49.065368\n",
      "INFO: Extracting 2 points for chunk nr 82 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 77 at resolution 0.2 extracted in:: 0:00:24.840812\n",
      "INFO: Extracting 2 points for chunk nr 83 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 73 at resolution 0.2 extracted in:: 0:00:49.568613\n",
      "INFO: Extracting 1 points for chunk nr 84 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 76 at resolution 0.2 extracted in:: 0:00:39.285941\n",
      "INFO: Extracting 2 points for chunk nr 85 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 75 at resolution 0.2 extracted in:: 0:00:50.771539\n",
      "INFO: Extracting 1 points for chunk nr 86 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 79 at resolution 0.2 extracted in:: 0:00:38.272959\n",
      "INFO: 2 points for chunk nr 64 at resolution 0.2 extracted in:: 0:01:45.426054\n",
      "INFO: Extracting 1 points for chunk nr 87 at resolution 0.2\n",
      "INFO: Extracting 1 points for chunk nr 88 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 78 at resolution 0.2 extracted in:: 0:00:51.268474\n",
      "INFO: Extracting 1 points for chunk nr 89 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 81 at resolution 0.2 extracted in:: 0:00:49.806272\n",
      "INFO: Extracting 1 points for chunk nr 90 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 87 at resolution 0.2 extracted in:: 0:00:17.065467\n",
      "INFO: Extracting 2 points for chunk nr 91 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 84 at resolution 0.2 extracted in:: 0:00:32.313592\n",
      "INFO: Extracting 1 points for chunk nr 92 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 83 at resolution 0.2 extracted in:: 0:00:35.252490\n",
      "INFO: Extracting 2 points for chunk nr 93 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 86 at resolution 0.2 extracted in:: 0:00:28.000182\n",
      "INFO: Extracting 3 points for chunk nr 94 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 88 at resolution 0.2 extracted in:: 0:00:29.531011\n",
      "INFO: Extracting 2 points for chunk nr 95 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 85 at resolution 0.2 extracted in:: 0:00:41.274145\n",
      "INFO: Extracting 2 points for chunk nr 96 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 89 at resolution 0.2 extracted in:: 0:00:28.566454\n",
      "INFO: Extracting 1 points for chunk nr 97 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 82 at resolution 0.2 extracted in:: 0:01:21.443551\n",
      "INFO: Extracting 2 points for chunk nr 98 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 90 at resolution 0.2 extracted in:: 0:00:34.243219\n",
      "INFO: Extracting 2 points for chunk nr 99 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 97 at resolution 0.2 extracted in:: 0:00:21.361369\n",
      "INFO: Extracting 3 points for chunk nr 100 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 92 at resolution 0.2 extracted in:: 0:00:46.057654\n",
      "INFO: Extracting 2 points for chunk nr 101 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 80 at resolution 0.2 extracted in:: 0:01:44.759509\n",
      "INFO: Extracting 3 points for chunk nr 102 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 91 at resolution 0.2 extracted in:: 0:00:57.945762\n",
      "INFO: Extracting 1 points for chunk nr 103 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 98 at resolution 0.2 extracted in:: 0:00:27.986015\n",
      "INFO: Extracting 2 points for chunk nr 104 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 99 at resolution 0.2 extracted in:: 0:00:33.836531\n",
      "INFO: Extracting 1 points for chunk nr 105 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 95 at resolution 0.2 extracted in:: 0:00:59.943550\n",
      "INFO: Extracting 1 points for chunk nr 106 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 103 at resolution 0.2 extracted in:: 0:00:19.220849\n",
      "INFO: Extracting 1 points for chunk nr 107 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 101 at resolution 0.2 extracted in:: 0:00:30.511190\n",
      "INFO: Extracting 1 points for chunk nr 108 at resolution 0.2\n",
      "INFO: 3 points for chunk nr 94 at resolution 0.2 extracted in:: 0:01:13.658912\n",
      "INFO: Extracting 1 points for chunk nr 109 at resolution 0.2\n",
      "INFO: 2 points for chunk nr 96 at resolution 0.2 extracted in:: 0:01:05.977471\n",
      "INFO: Extracting 1 points for chunk nr 110 at resolution 0.2\n",
      "INFO: 3 points for chunk nr 100 at resolution 0.2 extracted in:: 0:00:51.419084\n",
      "INFO: Extracting 1 points for chunk nr 111 at resolution 0.2\n",
      "INFO: 1 points for chunk nr 106 at resolution 0.2 extracted in:: 0:00:27.882808\n",
      "INFO: 1 points for chunk nr 107 at resolution 0.2 extracted in:: 0:00:24.240124\n",
      "INFO: 1 points for chunk nr 105 at resolution 0.2 extracted in:: 0:00:35.739812\n",
      "INFO: 2 points for chunk nr 104 at resolution 0.2 extracted in:: 0:00:43.578024\n",
      "INFO: 1 points for chunk nr 109 at resolution 0.2 extracted in:: 0:00:30.535519\n",
      "INFO: 1 points for chunk nr 108 at resolution 0.2 extracted in:: 0:00:35.519200\n",
      "INFO: 2 points for chunk nr 93 at resolution 0.2 extracted in:: 0:01:55.709747\n",
      "INFO: 1 points for chunk nr 111 at resolution 0.2 extracted in:: 0:00:23.886322\n",
      "INFO: 1 points for chunk nr 110 at resolution 0.2 extracted in:: 0:00:46.155551\n",
      "INFO: 3 points for chunk nr 102 at resolution 0.2 extracted in:: 0:02:10.513102\n",
      "INFO: Removing assets within asset folder projects/earthengine-legacy/assets/users/cwespestad_SIG/tmp_esbae_250115_190025\n",
      "INFO: Removing asset folder projects/earthengine-legacy/assets/users/cwespestad_SIG/tmp_esbae_250115_190025.\n",
      "WARNING: Not fully processed. Will retry at a higher aggregation level.\n",
      "INFO: Checking for points not processed at the current aggregation level.\n",
      "INFO: Found already processed files. Identifying already processed points and skipping them.\n",
      "INFO: Found 178 already processed points\n",
      "INFO: This batch of points has successfully been processed.\n",
      "INFO: Extraction of time-series has been finished for all points.\n",
      "INFO: Cleaning up temporary Earth Engine assets created during the processing.\n"
     ]
    }
   ],
   "source": [
    "esbae.get_time_series_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": " (venv) Sample Based Area Estimation",
   "language": "python",
   "name": "venv-esbae_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
