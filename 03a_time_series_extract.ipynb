{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e262b60-a61c-4fb6-adfb-c00d1ebda073",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>eSBAE - Notebook Series - Part 3, version 0.4, March 2023. Andreas Vollrath, UN-Food and Agricultural Organization, Rome</i>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64fe01-50b8-4280-9629-1445ad541e45",
   "metadata": {},
   "source": [
    "![title](images/header.png)\n",
    "\n",
    "# II - eSBAE Time-Series Extraction\n",
    "### Extract various time-series data for large sets of points from Google Earth Engine\n",
    "-------\n",
    "\n",
    "This notebook takes you through the process of extracting time-series for a set of points using [Google's Earth Engine](https://earthengine.google.com/). The script is optimized to deal with thousands of points and will use parallelization to efficiently extract the information from the platform.\n",
    "\n",
    "**You will need**:\n",
    "- a valid Earth Engine account ([sign up here](https://code.earthengine.google.com/register))\n",
    "- an uploaded table of points (Feature Collection) \n",
    "- the table needs a unique point identifier (Point ID)\n",
    "\n",
    "**You should be aware, that:** \n",
    "\n",
    "- This notebook does **not need huge resources**, as processing is done on the platform. A **m2 instance** or lower is sufficient.  \n",
    "- The extraction can take up to days (>100000 points). If you are on SEPAL, make use of the **\"keep instance running\"** option within the user report dashboard. However, **do not forget** to shut down your machine once processing finished. \n",
    "- A logfile is created within your tmp-folder. Interruption of connectivity to the SEPAL server may lead to block the output of the Jupyter notebook. **This does not mean the processing stopped.** You can see in esbae_log_(time) if the processing is still on going. \n",
    "- You can restart the kernel and execute all cells, and extraction will **start where it stopped**. This is also valid, if your instance has been shut down before processing was completely finished."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f9d9a-8a0d-4d85-b134-f0bda3727152",
   "metadata": {},
   "source": [
    "### 1 - Import libs\n",
    "\n",
    "**ONLY EXECUTE THIS CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e78de-8687-4632-8586-9ca964b31045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "from sampling_handler.time_series import ts_extract\n",
    "\n",
    "# initialize EE    \n",
    "try:\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c04e79-5bfe-48d9-8412-c17707d7c5e9",
   "metadata": {},
   "source": [
    "### 2 - Basic Input Variables\n",
    "\n",
    "**FILL IN YOUR INPUTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8d21f-1d84-44b2-9b44-3458bc7ff444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project name (will be used for folder creation in your hone folder)\n",
    "project = 'myESBAE'\n",
    "\n",
    "# define the column name foe your unique point identifier within your Feature collection\n",
    "point_id_name = \"point_id\"\n",
    "\n",
    "# Point Feature Collection from where to extract points\n",
    "points_fc = ee.FeatureCollection(\n",
    "    \"users/<username>/<points_fc_name>\"\n",
    ").sort(point_id_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b7557-3d18-43bc-a6c3-5bd8a7b8daba",
   "metadata": {},
   "source": [
    "#### 2c - Time-series parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3041347-3240-4952-af6a-a27c2dab7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start of calibration period (mainly for bfast)\n",
    "start_calibration = \"2010-01-01\"  # YYYY-MM-DD format\n",
    "\n",
    "# Actual period of interest, i.e. monitoring period\n",
    "start_monitor =     \"2015-01-01\"  # YYYY-MM-DD format\n",
    "end_monitor =       \"2023-01-01\"  # YYYY-MM-DD format\n",
    "\n",
    "# Directory where output and temp files will go\n",
    "outdir = f\"/home/sepal-user/{project}/03_time_series_extraction\"\n",
    "\n",
    "# select the bands to extract\n",
    "bands = [\n",
    "    #'blue', \n",
    "    'green', 'red', 'nir', 'swir1', 'swir2',           # reflectance bands\n",
    "    'ndfi', 'ndmi', #'mndwi', 'nbr', 'ndvi'            # available ratios\n",
    "    'brightness', 'greenness', 'wetness'               # tasseled cap\n",
    "]\n",
    "\n",
    "# select the band for univariate ts-analysis (has to be inside bands list)\n",
    "ts_band = 'ndfi'\n",
    "\n",
    "# select the resolution to which the satellite data will be resized.\n",
    "scale = 30  # in meters (70 m is half ha, relates to FAO forest definition)\n",
    "\n",
    "### DO NOT CHANGE YET ###\n",
    "satellite='Landsat'  # this is going to be Surface Reflactance, Collection 2, Tier 1 data only\n",
    "max_cloud_cover = 75  # in percentage (0-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4dc5b2-3d18-429e-ae4a-5b16f677448a",
   "metadata": {},
   "source": [
    "### 3- Algorithm parameter settings\n",
    "\n",
    "**Edit for advanced users, otherwise just execute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe65b6-268e-418d-bab0-0837542a1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# landsat related parameters\n",
    "lsat_params = {\n",
    "    'l9':     True,\n",
    "    'l8':     True,\n",
    "    'l7':     True,\n",
    "    'l5':     True,\n",
    "    'l4':     True,\n",
    "    'brdf':   True,\n",
    "    'bands':  bands,\n",
    "    'max_cc': max_cloud_cover\n",
    "}\n",
    "\n",
    "\n",
    "### GATHER ALL INFO INTO A DICT #####\n",
    "config_dict = {\n",
    "    'work_dir':                         outdir,\n",
    "    'workers':                          10,\n",
    "    'max_points_per_chunk':             75,\n",
    "    'grid_size_levels':                 [0.1, 0.05, 0.025],  # definition of chunk sizes in degrees  \n",
    "    'lsat_params':                      lsat_params,\n",
    "    'ts_params': {\n",
    "        'start_calibration':            start_calibration,\n",
    "        'start_monitor':                start_monitor,\n",
    "        'end_monitor':                  end_monitor,\n",
    "        'point_id':                     point_id_name,\n",
    "        'bands':                        bands,\n",
    "        'ts_band':                      ts_band,\n",
    "        'satellite':                    satellite,\n",
    "        'scale':                        scale,\n",
    "        'max_cc':                       max_cloud_cover,\n",
    "    },    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5c28df-5381-413c-924d-23830b97b87e",
   "metadata": {},
   "source": [
    "### 4 - Run the time-series data extraction\n",
    "\n",
    "**Execute only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ccf187-bba1-4e1a-a493-d646f51b9fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts_extract.extract(points_fc, config_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
